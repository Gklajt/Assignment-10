{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Model building b) Model testing c) Applying the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Identify Dependent and Independent Variables </br>\n",
    "2) Split Data into test and training Sets </br>\n",
    "3) Fit it into a model </br>\n",
    "4) predict test dependent variable (test_y) based on test independant variable (test_x) and  find the accuracy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Set is data set used to train the model to find potential relationship in data. </br>\n",
    "Test Set is Data used to predict the dependent variable based up on the Models's learning of relationship between independent variable and dependent variable from training set and to measure accuracy of the model's prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining predictions of multiple models to produce better result that by using single model</br>\n",
    "Basic principle is that a group of week learners come together to form a strong learner\n",
    "\n",
    "Bagging :- Several estimators are built independently on subsets of the data and their predictions are\n",
    "averaged. Typically the combined estimator is usually better than any of the single base estimator.  </br>\n",
    "Bagging can reduce variance with little to no effect on bias.</br>\n",
    "\n",
    "Boosting:- Base estimators are built sequentially. Each subsequent estimator focuses on the weaknesses of\n",
    "the previous estimators. In essence several weak models \"team up\" to produce a powerful\n",
    "ensemble model.</br>\n",
    "Boosting can reduce bias without incurring higher variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1)  \"cross validation\" In this method the dataset splits into two section, testing and training datasets,\n",
    "the testing dataset will only test the model while, in training dataset, the datapoints will come up with the model.</br>\n",
    "2) Reduce Architecture complexity</br>\n",
    "3) Use more data</br>\n",
    "4) Regularization </br>\n",
    "5) Ensembling</br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
